# 300分钟吃透分布式缓存

300分钟吃透分布式缓存
微博大神教你支撑百万QPS的核心技术
讲师：陈波  新浪微博平台架构技术专家
共35讲 / 已全部更新10692人已购买

分布式缓存

百万QPS的核心技术

# 课程目录

开篇寄语
开篇寄语：缓存，你真的用对了吗？
第一章：缓存的原理、引入及设计
第01讲：业务数据访问性能太低怎么办？
第02讲：如何根据业务来选择缓存模式和组件？
第03讲：设计缓存架构时需要考量哪些因素？
第二章：7大缓存经典问题
第04讲：缓存失效、穿透和雪崩问题怎么处理？
第05讲：缓存数据不一致和并发竞争怎么处理？
第06讲：Hot Key和Big Key引发的问题怎么应对？
第三章：Memcached的原理及架构剖析
第07讲：MC为何是应用最广泛的缓存组件？
第08讲：MC系统架构是如何布局的？
第09讲：MC是如何使用多线程和状态机来处理请求命令的？
第四章：Memcached进阶
第10讲：MC是怎么定位key的?
第11讲：MC如何淘汰冷key和失效key?
第12讲：为何MC能长期维持高性能读写？
第13讲：如何完整学习MC协议及优化client访问？
第五章：分布式Memcached实战
第14讲：大数据时代，MC如何应对新的常见问题？
第15讲：如何深入理解、应用及扩展 Twemproxy？
第六章：Redis原理、协议及使用
第16讲：常用的缓存组件Redis是如何运行的？
第17讲：如何理解、选择并使用Redis的核心数据类型？
第18讲：Redis协议的请求和响应有哪些“套路”可循？
第七章：Redis进阶（上）
第19讲：Redis系统架构中各个处理模块是干什么的？
第20讲：Redis如何处理文件事件和时间事件？
第21讲：Redis读取请求数据后，如何进行协议解析和处理?
第22讲：怎么认识和应用Redis内部数据结构？
第八章：Redis进阶（下）
第23讲：Redis是如何淘汰key的？
第24讲：Redis崩溃后，如何进行数据恢复的？
第25讲： Redis是如何处理容易超时的系统调用的？
第26讲：如何大幅成倍提升Redis处理性能？
第九章：分布式Redis实战
第27讲：Redis是如何进行主从复制的？
第28讲：如何构建一个高性能、易扩展的Redis集群？
第29讲：从容应对亿级QPS访问，Redis还缺少什么？
第十章：深入分布式缓存
第30讲：面对海量数据，为什么无法设计出完美的分布式缓存体系？
第31讲：如何设计足够可靠的分布式缓存体系，以满足大中型移动互联网系统的需要？
第32讲：一个典型的分布式缓存系统是什么样的？
第十一章：应用场景案例解析
第33讲：如何为秒杀系统设计缓存体系？
第34讲：如何为海量计数场景设计缓存体系？
第35讲：如何为社交feed场景设计缓存体系？

# 课程信息



课程背景
- 2018年10月16日，新浪微博又一次迎来“官宣”，瞬间流量暴增击垮服务器。

- 2018年11月11日，淘宝 App 大量的订单，导致用户无法修改邮寄地址。

- 2019年9月，周杰伦新专辑发布，QQ 音乐迎来短暂宕机。

这些场景的产生，都与缓存技术有着密不可分的关系。新浪微博在2019 年日活用户超 2亿，每日新发 Feed 1～2亿，历史数据高达千亿级。核心接口可用性要达到 99.99%，响应时间在 10～60ms 以内，核心单个业务的数据访问量高达百万级 QPS。



如果数据信息都从 DB 中加载，将会是一个无法忍受的漫长等待过程，而支撑新浪微博的，便是良好的架构和优秀的缓存体系，甚至可以说：缓存技术，是提升系统性能、改善用户体验的唯一解决之道。



缓存技术 是提升系统性能 改善用户体验的唯一解决之道



在新浪微博一线工作十余年的陈波老师，在微博 Feed 流及分布式储存具有多年的实战经验。课程从底层原理开始，再现穿透、雪崩等六大经典问题和解决方案。从核心基础入手，加强 Memcached 和 Redis 进阶知识点，升级到讲解分布式缓存 CAP。



内容会以 3 个实际应用场景为例，深度分析缓存在秒杀系统、计数器、Feed 流中的应用，可以帮助你收获不同场景下、不同设计策略的启发，给你一套完整的缓存系列能力进阶图谱。



缓存系列能力进阶图谱 



课程讲师
陈波
新浪微博平台架构技术专家
微博平台缓存从0到1主要工程师之一，曾参与撰写技术畅销书《深入分布式缓存》。

 2008年加入新浪，2009年起着手微博 Feed 平台系统的研发及架构工作，深度参与了微博若干版本的所有业务的开发和架构改进。

从2013年至今，他负责微博平台基础架构相关的研发工作，经历了新浪微博从起步到月活数亿用户的大型互联网系统的技术演进过程。

学习收获
1.掌握redis/Memcached底层实现与高级特性
2.剖析缓存在秒杀、计数器、Feed流中的应用
3.掌握大规模穿透、雪崩等经典问题的解决方案
4.揭秘新浪微博的百万级QPS技术核心
课程大纲

课程大纲

课程大纲

![img](assets/CgoB5l2wEwOAafKYAAMTF_-6GIc809.jpg)



课程大纲

订阅须知

1.本专栏已更新完毕，共 35 讲；

2.支持 视频+音频+图文 3种阅读形式；

3.购买后在拉勾 App - 课程，可永久观看课程；

4.视频课程为虚拟商品，一旦售出不可申请退款；

5.本课程版权归拉勾所有，严禁翻录，违者必究；

6. 如有问题请咨询客服同学，召唤客服>>>

精选留言
**科

9
本课学习总结：缓存是一把双刃剑，既然是双刃剑那么必定存在利大于弊，如何能让利(提升访问性能、增强可扩展性、降低网络拥堵、减轻服务负载）大于弊(缓存的引入必定增加了服务的复杂性、缓存部署&运行成本高、一致性问题<1.缓存和原始数据之间的一致性；2.缓存内部数据多版本、可用性、分区性等问题>)呢？当然在于使用者，这就是考验使用者水平的时候到了；如果对缓存的原理玩的溜溜，那么使用按道理来说问题不大，如果玩不转还想使用，那有可能就是关公面前耍大刀，结果可想而知😇！！
缓存的引入就是为了解决数据访问速度，那么缓存的基本思想就是利用时间局限性原理（脑门打开-》空间局限性原理），采用的手段就是空间换时间，这个空间目前来说是很贵的噢。在做架构设计的时候要权衡访问延迟和成本之间tradeoff(权衡取舍)；一个好的架构师能把复杂的问题简单化，简单的问题搞成没有问题，而烂大街的架构师就是把简单问题搞复杂；换句话说存在过度设计，架构是演进的！！！
**科

5
本课总结：
缓存的读写模式：
1.Cache Aside模式：写->先写DB然后，删除cachekey；通过监听DB的日志变化驱动cache的更新；读：cache命中直接返回，否则读DB，回写cache，然后返回；特点->采用lazy计算特性，以DB的数据为准；适用于一致性强的场合、构建cache复杂的场合；业务方需要关注cache和DB，相对来说比较繁琐；
2.Read/Write through模式：写->cache不存在，更新DB；cache存在更新cache+DB；读->cache命中直接返回，未命中由缓存服务从DB读取并回写cache返回；特点->该模式采用了存储服务负责数据读写，隔离型更好，热数据更友好，业务只需要与存储服务打交道；适用场景->数据有冷热区分；
3.Write Behind Caching模式：写->只更新缓存，缓存服务异步更新DB；读：未命中后由缓存服务加载写Cache返回；特点->写性能最高，定期异步更新，存在数据丢失概率；适用场景->写频率超高，需要合并，但是对数据丢失不敏感；
以上三种模式的使用场景是tradeoff，没有完美的解决方案，只有根据自己的业务场景尽可能做到当下完美即可；

缓存分类：
1.按照宿主层次分类：a.本地缓存->业务进程内的缓存，与业务进程同生共死！性能当然杠杠的。b.进程间缓存->本机独立运行的缓存，有点类似于古代一大家住在一起沟通交流很方便，各自有各自的空间，但是时间久了就会出现纠纷；c.远程缓存->跨机房部署的缓存，类似于分家了，住的远了，交流就只能通过电话，但是电话有可能信号不好，等存在其他未知风险；
2.按照存储介质分类：内存型；持久化型；内存+持久化型；
编辑回复： 同学加油~
*源

5
首先检查 key是否过期失效，如果失效则进行回收淘汰，然后继续小循环；如果遇到一个没失效的 key，则回收该 key 并退出 TEMP LRU 的清理工作。
老师，既然key没有失效为什么还回收该key？
讲师回复： 因为temp_lru里面的都是短命key，即1分钟内会过期的key，队尾的key肯定小于1分钟，在维护线程对这些短命key处理时，如果所有的key都还没失效，会在队尾清理一个最快就要过期的key，同时停止本次对temp_lru的维护循环，这样做的目的：即便mc里的key全部都是短命key，一次轮询至少也会清理掉一个key。
*群

3
说实话，干货还是挺多的，不管是职业面试还是夯实自己的技术都有非常大的帮助，比较欣赏老师的逻辑能力，遇到一个好老师不容易，下一步满满的实操。
**根

3
虽然之前学过redis分布式，但是觉得还是挺有收获的。从算法原理到原生实现，再到框架的运用，使得更容易理解，通俗易懂。感觉很满意。
*齐

2
疑问：
预防缓存雪崩时，方案一中，"部分或所有读 DB 的请求进行 failfast 立即返回",failfast,是否意味着 请求的服务不可用？
这样似乎并没有解决问题，failfast后，请求返回，没有获取到数据，要如何处理呢？还是说提示“服务不可用呢？”
讲师回复： 当DB压力过大负荷严重过载时，会出现DB请求严重变慢、阻塞，甚至进程崩溃，最终导致整个系统丢数据、不可用。 此时可以通过DB读写开关，降低DB压力，优先保证写，同时支持一部分读，可以在不丢数据的情况下，尽可能服务更多的用户。部分用户failfast，请求失败，比整个系统不可用、所有用户请求失败要好，这也算一种工程最佳实践吧。
**杰

2
老师，讲的很细致，但是之前接触的不多，可以有一些案例实战吗？
编辑回复： 后面的课程会涉及案例哦~加油~
**召

2
老师非常专业，课程非常系统，思路清晰，受益匪浅。
**均

2
课程非常不错，每一个点都深入到具体原理。几乎概括了我工作中所有的redis问题，值得拥有。
**东

2
这是我学过的最具干货的课程了，无论从知识点的聚焦度，还是从知识点的发散思考方面，都会给学习课程的我们一个很大的思考空间，并且无盲点的手把手教学，让新手也很容易上手学习，知识点干货满满，期待老师的下一步大作
*红

2
陈波老师讲的非常实用，在大部分公司工作中都能运用得上。也开阔了自己的视野，学习了很多技巧，和编程思想。会一直支持老师的课程的！
**发

1
我想问的是trigger组件的角色是什么嘛？Db的更新日志，MYSQL的话是指的是binlog嘛？
讲师回复： 读取并解析mysql的binlog，然后进行一些业务逻辑处理，更新缓存数据。
**用户8616

1
老师您好，请问一下把一个大key分成多个小key请问需要怎么操作呢，就算设置的超时时间是一样的，但是分解开来的程序执行也是需要时间的吧，这样如果访问是不是会容易丢失数据呢？上一章节的内容都处理过，但是这章节的内容并没有处理过，所以看着也有点难受，没有例子的话
讲师回复： "“分解开来的程序执行也是需要时间的吧” 是的，但分解的执行程序就分散在众多的前端，整体性能要远好于从db中的计算及加载。 “这样如果访问是不是会容易丢失数据呢” 设计好分片策略，如果缓存数据过期，而正好需要这个分片，那就从db中加载这个分片即可，这样只用加载1/n 的数据即可。比如10000条记录，分10片，如果其中一片在缓存被踢出，那就只用加载1/10的数据。 分片存储本身是一个复杂度较高的存储方案，一般业务存储优先考虑其他常规方案，只有常规方案无法满足业务需求是，才采用分片存储方案。"
**超

1
HOT LRU 中回收和迁移的 keys 数为 0。
这个时什么情况产生的?不是非active就移入cold吗，失效key删除，有效key要么移入warm要么移入cold，所以只要执行了hot的清理工作，keys就不会为0吧？
讲师回复： 这个问题很赞，这里实际需要进一步细分。对于hot lru，如果这个 key 的状态是 ACTIVE，则迁移到 WARM LRU。对于非ACTIVE状态的key，如果HOT LRU内存占用超过限制，则迁移到 COLD LRU，否则进行纾困性清理掉该key，注意这种纾困性清理操作一般不会发生，一旦发生时，虽然会清理掉该key，但操作函数此时也认定本次操作回收和清理keys数仍然为0。
**庆

1
缓存雪崩：
三种方案好像都没有解决 第二种情况: "在较大的流量洪峰到临之时，如果大流量 key 比较集中，正好在某 1～2 个缓存节点"  这个用 一致性哈希+rehash 已经无法解决了？这个时候怎么处理呢？
讲师回复： 对于流量洪峰来临，如果key比较集中在某个缓存节点，网卡打满，负荷过载，节点宕机，这时候如果rehash，只是把流量再转移到其他节点，也会导致其他节点过载而异常。所以这种场景，没法用rehash解决，而需要采用其他方案。本节最后提了三种方案可以参考，比如，采用多个副本，把访问分散到不同副本，或者没有足够资源，就拒绝部分访问，确保大部分用户可用或主体功能可用等。
**东

1
牛逼!
多种实用的修改扩展redis实现的方案，通过构建longset等特定的数据结构大幅优化了，用户关注列表和feed流计数的空间消耗问题。
通过增量aof和全量rdb完善主从同步方案。通过中心化的clusterManager管理配置，减少slave负担，并提供完善的集群管理功能。
😏😏😏
*齐

1
“需要考虑是采用一致性 Hash 分布的访问漂移策略”？这里的"漂移策略"是指什么？还是笔误呢？
讲师回复： 漂移策略即rehash策略，就是指：当key所在的服务节点异常无法访问时，将key的访问节点调整（漂移）到其他固定服务节点。
*毅

1
Redis 5.0 集群 默认是读写分离模式还是读写都在主库的 ?
讲师回复： 读写分离还是读写都操作master是由client决定的。但一般来讲，master下需要挂载至少一个slave，以避免master异常时，没有slave来顶替master。这样，读写分离是默认选项。 在实际线上操作时，成本及性能考虑，写只操作master，读优先操作slave，如果master压力不大，读可以随机或按权重同时操作在slave和master上。
**科

1
本课总结：
设计缓存架构需要考量的因素：
1.缓存组件的选择；有两大选择维度，一种是采用市面上现有的组件比如redis等等；另外一种就是自己研发或者在开源的技术上二次开发，这个要求相对比较高，需要技术人员能hold的住遇到的问题，比会使用要求高了不止一个量级；组件选择需要结合自己的业务场景选择适合自己业务的，千万别搞的花里胡哨，没有实际价值的东西。组件选择需要了解每一种组件能解决什么问题、适应什么场景、有什么坑；这个坑是需要关注的；别为了解决一个问题，而引入一个大坑。
2.缓存的数据结构设计；分为简单数据类型比如KV、复杂数据类型比如集合类型；
3.缓存的分布设计；目前分布式算法主要有取模和一致hash，取模的方案简单，每个key会缓存在确定的节点上；一致hash方案复杂，一个key对应的节点不确定，可以再缓存节点异常时，将失效的节点的数据访问均衡分布到其他正常的节点上，从而更好的保证了缓存系统的稳定性，但是这里也有坑(后面会总结)；分布式读写的实现目前就分客户端和代理；客户端相对来说性能高，但是需要感知分布策略，当缓存发生变化时，需要通知client，避免出现异常，实现复杂；代理模式复杂路由，client只需要访问proxy，缓存逻辑及部署的变化都由proxy完成，对用户端和业务来说是友好的，但是访问多了一次跳转，性能有一定的下降(互联网中多一跳就会引入不确定性，风险就会上升)；缓存的运行分布主要是指缓存节点如何实现动态拆分，把部分数据动态迁移到其他缓存节点，目前市面的做法就是代理来做、缓存Server来做、不支持迁移等。
综合以上思路得出选型的<知识树>;
用什么？如何使用？如何部署？如何动态扩容？如何监控？如何验证效果？

**才

1
老师讲的很棒，后面的章节什么时候更新呢 好期待

