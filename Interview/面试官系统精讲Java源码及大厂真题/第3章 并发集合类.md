**第3章 并发集合类**

第3章 并发集合类

- 15 CopyOnWriteArrayList 源码解析和设计思路
- 16 ConcurrentHashMap 源码解析和设计思路
- 17 并发 List、Map源码面试题
- 18 场景集合：并发 List、Map的应用场景

第3章 并发集合类

# 15 CopyOnWriteArrayList 源码解析和设计思路

15 CopyOnWriteArrayList 源码解析和设计思路

更新时间：2019-09-26 09:36:57

![img](https://img2.mukewang.com/5d89760c000109d506400359.jpg)

![img](https://www.imooc.com/static/img/column/bg-l.png)![img](https://www.imooc.com/static/img/column/bg-r.png)

古之立大事者，不唯有超世之才，亦必有坚韧不拔之志。

——苏轼



## 引导语

在 ArrayList 的类注释上，JDK 就提醒了我们，如果要把 ArrayList 作为共享变量的话，是线程不安全的，推荐我们自己加锁或者使用 Collections.synchronizedList 方法，其实 JDK 还提供了另外一种线程安全的 List，叫做 CopyOnWriteArrayList，这个 List 具有以下特征：

1. 线程安全的，多线程环境下可以直接使用，无需加锁；
2. 通过锁 + 数组拷贝 + volatile 关键字保证了线程安全；
3. 每次数组操作，都会把数组拷贝一份出来，在新数组上进行操作，操作成功之后再赋值回去。



## 1 整体架构

从整体架构上来说，CopyOnWriteArrayList 数据结构和 ArrayList 是一致的，底层是个数组，只不过 CopyOnWriteArrayList 在对数组进行操作的时候，基本会分四步走：

1. 加锁；
2. 从原数组中拷贝出新数组；
3. 在新数组上进行操作，并把新数组赋值给数组容器；
4. 解锁。

除了加锁之外，CopyOnWriteArrayList 的底层数组还被 volatile 关键字修饰，意思是一旦数组被修改，其它线程立马能够感知到，代码如下：

```
private transient volatile Object[] array;
```

整体上来说，CopyOnWriteArrayList 就是利用锁 + 数组拷贝 + volatile 关键字保证了 List 的线程安全。



### 1.1 类注释

我们看看从 CopyOnWriteArrayList 的类注释上能得到哪些信息：

1. 所有的操作都是线程安全的，因为操作都是在新拷贝数组上进行的；
2. 数组的拷贝虽然有一定的成本，但往往比一般的替代方案效率高；
3. 迭代过程中，不会影响到原来的数组，也不会抛出 ConcurrentModificationException 异常。

接着我们来看下 CopyOnWriteArrayList 的核心方法源码。



## 2 新增

新增有很多种情况，比如说：新增到数组尾部、新增到数组某一个索引位置、批量新增等等，操作的思路还是我们开头说的四步，我们拿新增到数组尾部的方法举例，来看看底层源码的实现：

```java
// 添加元素到数组尾部
public boolean add(E e) {
    final ReentrantLock lock = this.lock;
    // 加锁
    lock.lock();
    try {
        // 得到所有的原数组
        Object[] elements = getArray();
        int len = elements.length;
        // 拷贝到新数组里面，新数组的长度是 + 1 的，因为新增会多一个元素
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        // 在新数组中进行赋值，新元素直接放在数组的尾部
        newElements[len] = e;
        // 替换掉原来的数组
        setArray(newElements);
        return true;
    // finally 里面释放锁，保证即使 try 发生了异常，仍然能够释放锁   
    } finally {
        lock.unlock();
    }
}
```

从源码中，我们发现整个 add 过程都是在持有锁的状态下进行的，通过加锁，来保证同一时刻只能有一个线程能够对同一个数组进行 add 操作。

除了加锁之外，还会从老数组中创建出一个新数组，然后把老数组的值拷贝到新数组上，这时候就有一个问题：都已经加锁了，为什么需要拷贝数组，而不是在原来数组上面进行操作呢，原因主要为：

1. volatile 关键字修饰的是数组，如果我们简单的在原来数组上修改其中某几个元素的值，是无法触发可见性的，我们必须通过修改数组的内存地址才行，也就说要对数组进行重新赋值才行。
2. 在新的数组上进行拷贝，对老数组没有任何影响，只有新数组完全拷贝完成之后，外部才能访问到，降低了在赋值过程中，老数组数据变动的影响。

简单 add 操作是直接添加到数组的尾部，接着我们来看下指定位置添加元素的关键源码（部分源码）：

```java
// len：数组的长度、index：插入的位置
int numMoved = len - index;
// 如果要插入的位置正好等于数组的末尾，直接拷贝数组即可
if (numMoved == 0)
    newElements = Arrays.copyOf(elements, len + 1);
else {
// 如果要插入的位置在数组的中间，就需要拷贝 2 次
// 第一次从 0 拷贝到 index。
// 第二次从 index+1 拷贝到末尾。
    newElements = new Object[len + 1];
    System.arraycopy(elements, 0, newElements, 0, index);
    System.arraycopy(elements, index, newElements, index + 1,
         numMoved);
}
// index 索引位置的值是空的，直接赋值即可。
newElements[index] = element;
// 把新数组的值赋值给数组的容器中
setArray(newElements);
```

从源码中可以看到，当插入的位置正好处于末尾时，只需要拷贝一次，当插入的位置处于中间时，此时我们会把原数组一分为二，进行两次拷贝操作。

最后还有个批量新增操作，源码我们就不贴了，底层也是拷贝数组的操作。



### 2.1 小结

从 add 系列方法可以看出，CopyOnWriteArrayList 通过加锁 + 数组拷贝+ volatile 来保证了线程安全，每一个要素都有着其独特的含义：

1. 加锁：保证同一时刻数组只能被一个线程操作；
2. 数组拷贝：保证数组的内存地址被修改，修改后触发 volatile 的可见性，其它线程可以立马知道数组已经被修改；
3. volatile：值被修改后，其它线程能够立马感知最新值。

3 个要素缺一不可，比如说我们只使用 1 和 3 ，去掉 2，这样当我们修改数组中某个值时，并不会触发 volatile 的可见特性的，只有当数组内存地址被修改后，才能触发把最新值通知给其他线程的特性。



## 3 删除

接着我们来看下指定数组索引位置删除的源码：

```java
// 删除某个索引位置的数据
public E remove(int index) {
    final ReentrantLock lock = this.lock;
    // 加锁
    lock.lock();
    try {
        Object[] elements = getArray();
        int len = elements.length;
        // 先得到老值
        E oldValue = get(elements, index);
        int numMoved = len - index - 1;
        // 如果要删除的数据正好是数组的尾部，直接删除
        if (numMoved == 0)
            setArray(Arrays.copyOf(elements, len - 1));
        else {
            // 如果删除的数据在数组的中间，分三步走
            // 1. 设置新数组的长度减一，因为是减少一个元素
            // 2. 从 0 拷贝到数组新位置
            // 3. 从新位置拷贝到数组尾部
            Object[] newElements = new Object[len - 1];
            System.arraycopy(elements, 0, newElements, 0, index);
            System.arraycopy(elements, index + 1, newElements, index,
                             numMoved);
            setArray(newElements);
        }
        return oldValue;
    } finally {
        lock.unlock();
    }
}
```

步骤分为三步：

1. 加锁；
2. 判断删除索引的位置，从而进行不同策略的拷贝；
3. 解锁。

代码整体的结构风格也比较统一：锁 + try finally +数组拷贝，锁被 final 修饰的，保证了在加锁过程中，锁的内存地址肯定不会被修改，finally 保证锁一定能够被释放，数组拷贝是为了删除其中某个位置的元素。



## 4 批量删除

数组的批量删除很有意思，接下来我们来看下 CopyOnWriteArrayList 的批量删除的实现过程：

```java
// 批量删除包含在 c 中的元素
public boolean removeAll(Collection<?> c) {
    if (c == null) throw new NullPointerException();
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        Object[] elements = getArray();
        int len = elements.length;
        // 说明数组有值，数组无值直接返回 false
        if (len != 0) {
            // newlen 表示新数组的索引位置，新数组中存在不包含在 c 中的元素
            int newlen = 0;
            Object[] temp = new Object[len];
            // 循环，把不包含在 c 里面的元素，放到新数组中
            for (int i = 0; i < len; ++i) {
                Object element = elements[i];
                // 不包含在 c 中的元素，从 0 开始放到新数组中
                if (!c.contains(element))
                    temp[newlen++] = element;
            }
            // 拷贝新数组，变相的删除了不包含在 c 中的元素
            if (newlen != len) {
                setArray(Arrays.copyOf(temp, newlen));
                return true;
            }
        }
        return false;
    } finally {
        lock.unlock();
    }
}
```

从源码中，我们可以看到，我们并不会直接对数组中的元素进行挨个删除，而是先对数组中的值进行循环判断，把我们不需要删除的数据放到临时数组中，最后临时数组中的数据就是我们不需要删除的数据。

不知道大家有木有似曾相识的感觉，ArrayList 的批量删除的思想也是和这个类似的，所以我们在需要删除多个元素的时候，最好都使用这种批量删除的思想，而不是采用在 for 循环中使用单个删除的方法，单个删除的话，在每次删除的时候都会进行一次数组拷贝(删除最后一个元素时不会拷贝)，很消耗性能，也耗时，会导致加锁时间太长，并发大的情况下，会造成大量请求在等待锁，这也会占用一定的内存。



## 5 其它方法



### 5.1 indexOf

indexOf 方法的主要用处是查找元素在数组中的下标位置，如果元素存在就返回元素的下标位置，元素不存在的话返回 -1，不但支持 null 值的搜索，还支持正向和反向的查找，我们以正向查找为例，通过源码来说明一下其底层的实现方式：

```java
// o：我们需要搜索的元素
// elements：我们搜索的目标数组
// index：搜索的开始位置
// fence：搜索的结束位置
private static int indexOf(Object o, Object[] elements,
                           int index, int fence) {
    // 支持对 null 的搜索
    if (o == null) {
        for (int i = index; i < fence; i++)
            // 找到第一个 null 值，返回下标索引的位置
            if (elements[i] == null)
                return i;
    } else {
        // 通过 equals 方法来判断元素是否相等
        // 如果相等，返回元素的下标位置
        for (int i = index; i < fence; i++)
            if (o.equals(elements[i]))
                return i;
    }
    return -1;
}
```

indexOf 方法在 CopyOnWriteArrayList 内部使用也比较广泛，比如在判断元素是否存在时（contains），在删除元素方法中校验元素是否存在时，都会使用到 indexOf 方法，indexOf 方法通过一次 for 循环来查找元素，我们在调用此方法时，需要注意如果找不到元素时，返回的是 -1，所以有可能我们会对这个特殊值进行判断。



### 5.2 迭代

在 CopyOnWriteArrayList 类注释中，明确说明了，在其迭代过程中，即使数组的原值被改变，也不会抛出 ConcurrentModificationException 异常，其根源在于数组的每次变动，都会生成新的数组，不会影响老数组，这样的话，迭代过程中，根本就不会发生迭代数组的变动，我们截几个图说明一下：

1. 迭代是直接持有原有数组的引用，也就是说迭代过程中，一旦原有数组的值内存地址发生变化，必然会影响到迭代过程，下图源码演示的是 CopyOnWriteArrayList 的迭代方法，我们可以看到迭代器是直接持有原数组的引用：
   ![图片描述](https://img.mukewang.com/5d88354300010c5111460592.png)
2. 我们写了一个 demo，在 CopyOnWriteArrayList 迭代之后，往 CopyOnWriteArrayList 里面新增值，从下图中可以看到在 CopyOnWriteArrayList 迭代之前，数组的内存地址是 962，请记住这个数字：
   ![图片描述](https://img.mukewang.com/5d8835800001ffca14040700.png)
3. CopyOnWriteArrayList 迭代之后，我们使用 add(“50”) 代码给数组新增一个数据后，数组内存地址发生了变化，内存地址从原来的 962 变成了 968，这是因为 CopyOnWriteArrayList 的 add 操作，会生成新的数组，所以数组的内存地址发生了变化：
   ![图片描述](https://img.mukewang.com/5d8835ac0001af7d13980550.png)
4. 迭代继续进行时，我们发现迭代器中的地址仍然是迭代之前引用的地址，是 962，而不是新的数组的内存地址：
   ![图片描述](https://img.mukewang.com/5d8835c20001596615780740.png)

从上面 4 张截图，我们可以得到迭代过程中，即使 CopyOnWriteArrayList 的结构发生变动了，也不会抛出 ConcurrentModificationException 异常的原因：CopyOnWriteArrayList 迭代持有的是老数组的引用，而 CopyOnWriteArrayList 每次的数据变动，都会产生新的数组，对老数组的值不会产生影响，所以迭代也可以正常进行。



## 6 总结

当我们需要在线程不安全场景下使用 List 时，建议使用 CopyOnWriteArrayList，CopyOnWriteArrayList 通过锁 + 数组拷贝 + volatile 之间的相互配合，实现了 List 的线程安全，我们抛弃 Java 的这种实现，如果让我们自己实现，你又将如何实现呢？

[14 简化工作：Guava Lists Maps 实际工作运用和源码](https://www.imooc.com/read/47/article/856)[16 ConcurrentHashMap 源码解析和设计思路](https://www.imooc.com/read/47/article/858)

精选留言 8

欢迎在这里发表留言，作者筛选后可公开显示

- [qq_oreo_5](https://www.imooc.com/u/6295658/articles)

  这个重入锁是全局的老师 就是add remove 用的是一把锁，是不能add时remove的

   0

  回复

  2019-11-27

- [Sicimike](https://www.imooc.com/u/3395084/articles)

  老师，文中说“如果我们简单的在原来数组上修改其中某几个元素的值，是无法触发可见性的，我们必须通过修改数组的内存地址才行，也就说要对数组进行重新赋值才行”。是因为线程工作内存中只拷贝了数组的引用，如果只改变数组中的值，那么线程工作内存中的值（数组引用）没有改变，所以不会触发可见性。是这样吗？

   1

  回复

  2019-11-12

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[Sicimike](https://www.imooc.com/u/3395084/articles)

    是的，底层原理主要是因为机器的 CPU 有多个导致的，我们在《03 Java 常用关键字理解》时有说到volatile关键字

    回复

    2019-11-17 10:54:19

- [licly](https://www.imooc.com/u/8096709/articles)

  为什么操作数组的时候使用getArray和setArray方法，而不是直接操作数组呢

   1

  回复

  2019-10-04

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    你说的操作数组是直接操作 array 的意思么？，array 是 private 的，无法直接操作哦。

    回复

    2019-10-08 12:54:19

  - [licly](https://www.imooc.com/u/8096709/articles)

    回复

    [文贺](https://www.imooc.com/u/8062574/articles)

    可是add方法就是CopyOnWriteArrayList类里的方法，就算array用private修饰，也可以直接访问的呀。为什么要在add里面使用setArray(newElements)呢，而不是直接this.array=newElements

    回复

    2019-10-08 19:23:40

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    哦，明白了，你说是在 CopyOnWriteArrayList 中为什么不直接用 this.array = 这种形式，非要用 set，我个人觉得两者都可以用，可能和作者习惯有关，你在项目中应该也碰到这两种写法，在一个 DTO 中写一端逻辑，有的同学喜欢用 setXXX，有的同学喜欢用 XXX =。

    回复

    2019-10-08 19:42:23

- [你存在我脑海里](https://www.imooc.com/u/6533826/articles)

  那老师，这种方式跟用Collections.synchronizeArrayList方式比较，哪种比较好呢？什么情景选择这两种不同的当时实现并发安全呢？

   1

  回复

  2019-09-27

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[你存在我脑海里](https://www.imooc.com/u/6533826/articles)

    个人看法哈，可能不完整也不全。在需要List是线程安全的时候，在生产环境，这两种写法我都看过有人用过，两者没有谁好谁坏之分。 但从两者的并发实现来看，有一个区别就是 synchronizedList 底层实现对读和写都加锁了(读写同一个锁，写时就无法读，读时也无法写)，而 CopyOnWriteArrayList 只对写进行了加锁，读是不加锁的，写时是可以读的，在读多的场景下，可能 CopyOnWriteArrayList 性能更好一些。 我个人观察，使用 CopyOnWriteArrayList 更多一些，我也更倾向于 CopyOnWriteArrayList，说的不全，仅供参考哈。

    回复

    2019-09-29 11:40:51

- [Elylic](https://www.imooc.com/u/3417562/articles)

  ArrayList查询快而增删慢，CopyOnWriteArrayList的并发安全性能好！

   0

  回复

  2019-09-27

- [soberyang](https://www.imooc.com/u/4604444/articles)

  这个效率比Synchronize包裹方式的效率低很多吧

   1

  回复

  2019-09-26

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[soberyang](https://www.imooc.com/u/4604444/articles)

    同学你好，这个主要看 synchronized 的代码怎么写了，看到了 synchronized 实现的代码才好比较。平时要用的话，如果数组不是很大的话，可以直接使用 CopyOnWriteArrayList，用的放心。

    回复

    2019-09-27 13:00:04

  - [weixin_小马哥_04277912](https://www.imooc.com/u/4277912/articles)

    回复[soberyang](https://www.imooc.com/u/4604444/articles)

    所以他更适合读操作多于写操作的场景，因为读操作没有加锁。

    回复

    2019-09-27 16:47:12

- [爱玩乒乓球的仲长芮澜](https://www.imooc.com/u/5576369/articles)

  老师，可不可以在专栏后面加餐两篇，写一写注解和xml相关的源码，迫切需要呀！

   2

  回复

  2019-09-26

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[爱玩乒乓球的仲长芮澜](https://www.imooc.com/u/5576369/articles)

    同学你好，注解和xml相关的源码范围太大了，你可以想几个你迫切需要的点，我写两篇手记是可以的，或者加我微信，不懂的可以随时问我：luanqiu0，加我备注一下来自慕课网哈。

    回复

    2019-09-27 13:04:29

- [海怪](https://www.imooc.com/u/1272304/articles)

  老师这个迭代为什么不用考虑线程安全的问题呢？如果有人更新的数组，而我还在迭代旧的数据那不就会造成结果不一致了吗？

   1

  回复

  2019-09-26

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[海怪](https://www.imooc.com/u/1272304/articles)

    同学你好，线程安全并不代表能得到最新实时的数据哈，正因为不管有没有更新，迭代时都是旧的数据，才保证了线程安全。

    回复

    2019-09-27 13:02:45

  - [weixin_小马哥_04277912](https://www.imooc.com/u/4277912/articles)

    回复[海怪](https://www.imooc.com/u/1272304/articles)

    CopyOnWriteArrayList保证的是最终一致性，也就是当下一次获取的时候可以拿到最新的值，这也是volatile的关键，所以他的所有读操作都没有加锁。

    回复

    2019-09-27 16:45:08

 

千学不如一看，千看不如一练

# 16 ConcurrentHashMap 源码解析和设计思路

16 ConcurrentHashMap 源码解析和设计思路

更新时间：2019-10-01 20:53:45

![img](https://img3.mukewang.com/5d89764e0001be1e06400359.jpg)

![img](https://www.imooc.com/static/img/column/bg-l.png)![img](https://www.imooc.com/static/img/column/bg-r.png)

与有肝胆人共事，从无字句处读书。

——周恩来

## 引导语

当我们碰到线程不安全场景下，需要使用 Map 的时候，我们第一个想到的 API 估计就是 ConcurrentHashMap，ConcurrentHashMap 内部封装了锁和各种数据结构来保证访问 Map 是线程安全的，接下来我们一一来看下，和 HashMap 相比，多了哪些数据结构，又是如何保证线程安全的。

## 1 类注释

我们从类注释上大概可以得到如下信息：

1. 所有的操作都是线程安全的，我们在使用时，无需再加锁；
2. 多个线程同时进行 put、remove 等操作时并不会阻塞，可以同时进行，和 HashTable 不同，HashTable 在操作时，会锁住整个 Map；
3. 迭代过程中，即使 Map 结构被修改，也不会抛 ConcurrentModificationException 异常；
4. 除了数组 + 链表 + 红黑树的基本结构外，新增了转移节点，是为了保证扩容时的线程安全的节点；
5. 提供了很多 Stream 流式方法，比如说：forEach、search、reduce 等等。

从类注释中，我们可以看出 ConcurrentHashMap 和 HashMap 相比，新增了转移节点的数据结构，至于底层如何实现线程安全，转移节点的具体细节，暂且看不出来，接下来我们细看源码。

## 2 结构

虽然 ConcurrentHashMap 的底层数据结构，和方法的实现细节和 HashMap 大体一致，但两者在类结构上却没有任何关联，我们看下 ConcurrentHashMap 的类图：
![图片描述](https://img.mukewang.com/5d883afd0001a01a04670199.png)
看 ConcurrentHashMap 源码，我们会发现很多方法和代码和 HashMap 很相似，有的同学可能会问，为什么不继承 HashMap 呢？继承的确是个好办法，但尴尬的是，ConcurrentHashMap 都是在方法中间进行一些加锁操作，也就是说加锁把方法切割了，继承就很难解决这个问题。

ConcurrentHashMap 和 HashMap 两者的相同之处：

1. 数组、链表结构几乎相同，所以底层对数据结构的操作思路是相同的（只是思路相同，底层实现不同）；
2. 都实现了 Map 接口，继承了 AbstractMap 抽象类，所以大多数的方法也都是相同的，HashMap 有的方法，ConcurrentHashMap 几乎都有，所以当我们需要从 HashMap 切换到 ConcurrentHashMap 时，无需关心两者之间的兼容问题。

不同之处：

1. 红黑树结构略有不同，HashMap 的红黑树中的节点叫做 TreeNode，TreeNode 不仅仅有属性，还维护着红黑树的结构，比如说查找，新增等等；ConcurrentHashMap 中红黑树被拆分成两块，TreeNode 仅仅维护的属性和查找功能，新增了 TreeBin，来维护红黑树结构，并负责根节点的加锁和解锁；
2. 新增 ForwardingNode （转移）节点，扩容的时候会使用到，通过使用该节点，来保证扩容时的线程安全。

## 3 put

ConcurrentHashMap 在 put 方法上的整体思路和 HashMap 相同，但在线程安全方面写了很多保障的代码，我们先来看下大体思路：

1. 如果数组为空，初始化，初始化完成之后，走 2；
2. 计算当前槽点有没有值，没有值的话，cas 创建，失败继续自旋（for 死循环），直到成功，槽点有值的话，走 3；
3. 如果槽点是转移节点(正在扩容)，就会一直自旋等待扩容完成之后再新增，不是转移节点走 4；
4. 槽点有值的，先锁定当前槽点，保证其余线程不能操作，如果是链表，新增值到链表的尾部，如果是红黑树，使用红黑树新增的方法新增；
5. 新增完成之后 check 需不需要扩容，需要的话去扩容。

具体源码如下：

```java
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    //计算hash
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        //table是空的，进行初始化
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();
        //如果当前索引位置没有值，直接创建
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            //cas 在 i 位置创建新的元素，当 i 位置是空时，即能创建成功，结束for自循，否则继续自旋
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        //如果当前槽点是转移节点，表示该槽点正在扩容，就会一直等待扩容完成
        //转移节点的 hash 值是固定的，都是 MOVED
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        //槽点上有值的
        else {
            V oldVal = null;
            //锁定当前槽点，其余线程不能操作，保证了安全
            synchronized (f) {
                //这里再次判断 i 索引位置的数据没有被修改
                //binCount 被赋值的话，说明走到了修改表的过程里面
                if (tabAt(tab, i) == f) {
                    //链表
                    if (fh >= 0) {
                        binCount = 1;
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            //值有的话，直接返回
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            //把新增的元素赋值到链表的最后，退出自旋
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    //红黑树，这里没有使用 TreeNode,使用的是 TreeBin，TreeNode 只是红黑树的一个节点
                    //TreeBin 持有红黑树的引用，并且会对其加锁，保证其操作的线程安全
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        //满足if的话，把老的值给oldVal
                        //在putTreeVal方法里面，在给红黑树重新着色旋转的时候
                        //会锁住红黑树的根节点
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            //binCount不为空，并且 oldVal 有值的情况，说明已经新增成功了
            if (binCount != 0) {
                // 链表是否需要转化成红黑树
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                //这一步几乎走不到。槽点已经上锁，只有在红黑树或者链表新增失败的时候
                //才会走到这里，这两者新增都是自旋的，几乎不会失败
                break;
            }
        }
    }
    //check 容器是否需要扩容，如果需要去扩容，调用 transfer 方法去扩容
    //如果已经在扩容中了，check有无完成
    addCount(1L, binCount);
    return null;
}
```

源码中都有非常详细的注释，就不解释了，我们重点说一下，ConcurrentHashMap 在 put 过程中，采用了哪些手段来保证线程安全。

### 3.1 数组初始化时的线程安全

数组初始化时，首先通过自旋来保证一定可以初始化成功，然后通过 CAS 设置 SIZECTL 变量的值，来保证同一时刻只能有一个线程对数组进行初始化，CAS 成功之后，还会再次判断当前数组是否已经初始化完成，如果已经初始化完成，就不会再次初始化，通过自旋 + CAS + 双重 check 等手段保证了数组初始化时的线程安全，源码如下：

```java
//初始化 table，通过对 sizeCtl 的变量赋值来保证数组只能被初始化一次
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    //通过自旋保证初始化成功
    while ((tab = table) == null || tab.length == 0) {
        // 小于 0 代表有线程正在初始化，释放当前 CPU 的调度权，重新发起锁的竞争
        if ((sc = sizeCtl) < 0)
            Thread.yield(); // lost initialization race; just spin
        // CAS 赋值保证当前只有一个线程在初始化，-1 代表当前只有一个线程能初始化
        // 保证了数组的初始化的安全性
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                // 很有可能执行到这里的时候，table 已经不为空了，这里是双重 check
                if ((tab = table) == null || tab.length == 0) {
                    // 进行初始化
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    sc = n - (n >>> 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

### 3.2 新增槽点值时的线程安全

此时为了保证线程安全，做了四处优化：

1. 通过自旋死循环保证一定可以新增成功。

在新增之前，通过 `for (Node[] tab = table;;)` 这样的死循环来保证新增一定可以成功，一旦新增成功，就可以退出当前死循环，新增失败的话，会重复新增的步骤，直到新增成功为止。

1. 当前槽点为空时，通过 CAS 新增。

Java 这里的写法非常严谨，没有在判断槽点为空的情况下直接赋值，因为在判断槽点为空和赋值的瞬间，很有可能槽点已经被其他线程赋值了，所以我们采用 CAS 算法，能够保证槽点为空的情况下赋值成功，如果恰好槽点已经被其他线程赋值，当前 CAS 操作失败，会再次执行 for 自旋，再走槽点有值的 put 流程，这里就是自旋 + CAS 的结合。

1. 当前槽点有值，锁住当前槽点。

put 时，如果当前槽点有值，就是 key 的 hash 冲突的情况，此时槽点上可能是链表或红黑树，我们通过锁住槽点，来保证同一时刻只会有一个线程能对槽点进行修改，截图如下：

![图片描述](https://img.mukewang.com/5d883acd0001833304130067.png)

1. 红黑树旋转时，锁住红黑树的根节点，保证同一时刻，当前红黑树只能被一个线程旋转，代码截图如下：
   ![图片描述](https://img.mukewang.com/5d883adb000166bb05880443.png)

通过以上 4 点，保证了在各种情况下的新增（不考虑扩容的情况下），都是线程安全的，通过自旋 + CAS + 锁三大姿势，实现的很巧妙，值得我们借鉴。

### 3.3 扩容时的线程安全

ConcurrentHashMap 的扩容时机和 HashMap 相同，都是在 put 方法的最后一步检查是否需要扩容，如果需要则进行扩容，但两者扩容的过程完全不同，ConcurrentHashMap 扩容的方法叫做 transfer，从 put 方法的 addCount 方法进去，就能找到 transfer 方法，transfer 方法的主要思路是：

1. 首先需要把老数组的值全部拷贝到扩容之后的新数组上，先从数组的队尾开始拷贝；
2. 拷贝数组的槽点时，先把原数组槽点锁住，保证原数组槽点不能操作，成功拷贝到新数组时，把原数组槽点赋值为转移节点；
3. 这时如果有新数据正好需要 put 到此槽点时，发现槽点为转移节点，就会一直等待，所以在扩容完成之前，该槽点对应的数据是不会发生变化的；
4. 从数组的尾部拷贝到头部，每拷贝成功一次，就把原数组中的节点设置成转移节点；
5. 直到所有数组数据都拷贝到新数组时，直接把新数组整个赋值给数组容器，拷贝完成。

关键源码如下：

```java
// 扩容主要分 2 步，第一新建新的空数组，第二移动拷贝每个元素到新数组中去
// tab：原数组，nextTab：新数组
private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
    // 老数组的长度
    int n = tab.length, stride;
    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range
    // 如果新数组为空，初始化，大小为原数组的两倍，n << 1
    if (nextTab == null) {            // initiating
        try {
            @SuppressWarnings("unchecked")
            Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        nextTable = nextTab;
        transferIndex = n;
    }
    // 新数组的长度
    int nextn = nextTab.length;
    // 代表转移节点，如果原数组上是转移节点，说明该节点正在被扩容
    ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
    boolean advance = true;
    boolean finishing = false; // to ensure sweep before committing nextTab
    // 无限自旋，i 的值会从原数组的最大值开始，慢慢递减到 0
    for (int i = 0, bound = 0;;) {
        Node<K,V> f; int fh;
        while (advance) {
            int nextIndex, nextBound;
            // 结束循环的标志
            if (--i >= bound || finishing)
                advance = false;
            // 已经拷贝完成
            else if ((nextIndex = transferIndex) <= 0) {
                i = -1;
                advance = false;
            }
            // 每次减少 i 的值
            else if (U.compareAndSwapInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex > stride ?
                                   nextIndex - stride : 0))) {
                bound = nextBound;
                i = nextIndex - 1;
                advance = false;
            }
        }
        // if 任意条件满足说明拷贝结束了
        if (i < 0 || i >= n || i + n >= nextn) {
            int sc;
            // 拷贝结束，直接赋值，因为每次拷贝完一个节点，都在原数组上放转移节点，所以拷贝完成的节点的数据一定不会再发生变化。
            // 原数组发现是转移节点，是不会操作的，会一直等待转移节点消失之后在进行操作。
            // 也就是说数组节点一旦被标记为转移节点，是不会再发生任何变动的，所以不会有任何线程安全的问题
            // 所以此处直接赋值，没有任何问题。
            if (finishing) {
                nextTable = null;
                table = nextTab;
                sizeCtl = (n << 1) - (n >>> 1);
                return;
            }
            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)
                    return;
                finishing = advance = true;
                i = n; // recheck before commit
            }
        }
        else if ((f = tabAt(tab, i)) == null)
            advance = casTabAt(tab, i, null, fwd);
        else if ((fh = f.hash) == MOVED)
            advance = true; // already processed
        else {
            synchronized (f) {
                // 进行节点的拷贝
                if (tabAt(tab, i) == f) {
                    Node<K,V> ln, hn;
                    if (fh >= 0) {
                        int runBit = fh & n;
                        Node<K,V> lastRun = f;
                        for (Node<K,V> p = f.next; p != null; p = p.next) {
                            int b = p.hash & n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        // 如果节点只有单个数据，直接拷贝，如果是链表，循环多次组成链表拷贝
                        for (Node<K,V> p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph & n) == 0)
                                ln = new Node<K,V>(ph, pk, pv, ln);
                            else
                                hn = new Node<K,V>(ph, pk, pv, hn);
                        }
                        // 在新数组位置上放置拷贝的值
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        // 在老数组位置上放上 ForwardingNode 节点
                        // put 时，发现是 ForwardingNode 节点，就不会再动这个节点的数据了
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                    // 红黑树的拷贝
                    else if (f instanceof TreeBin) {
                        // 红黑树的拷贝工作，同 HashMap 的内容，代码忽略
                        …………
                        // 在老数组位置上放上 ForwardingNode 节点
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                }
            }
        }
    }
}
```

扩容中的关键点，就是如何保证是线程安全的，小结有如下几点：

1. 拷贝槽点时，会把原数组的槽点锁住；
2. 拷贝成功之后，会把原数组的槽点设置成转移节点，这样如果有数据需要 put 到该节点时，发现该槽点是转移节点，会一直等待，直到扩容成功之后，才能继续 put，可以参考 put 方法中的 helpTransfer 方法；
3. 从尾到头进行拷贝，拷贝成功就把原数组的槽点设置成转移节点。
4. 等扩容拷贝都完成之后，直接把新数组的值赋值给数组容器，之前等待 put 的数据才能继续 put。

扩容方法还是很有意思的，通过在原数组上设置转移节点，put 时碰到转移节点时会等待扩容成功之后才能 put 的策略，来保证了整个扩容过程中肯定是线程安全的，因为数组的槽点一旦被设置成转移节点，在没有扩容完成之前，是无法进行操作的。

## 4 get

ConcurrentHashMap 读的话，就比较简单，先获取数组的下标，然后通过判断数组下标的 key 是否和我们的 key 相等，相等的话直接返回，如果下标的槽点是链表或红黑树的话，分别调用相应的查找数据的方法，整体思路和 HashMap 很像，源码如下：

```java
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    //计算hashcode
    int h = spread(key.hashCode());
    //不是空的数组 && 并且当前索引的槽点数据不是空的
    //否则该key对应的值不存在，返回null
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (e = tabAt(tab, (n - 1) & h)) != null) {
        //槽点第一个值和key相等，直接返回
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.val;
        }
        //如果是红黑树或者转移节点，使用对应的find方法
        else if (eh < 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        //如果是链表，遍历查找
        while ((e = e.next) != null) {
            if (e.hash == h &&
                ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
```

## 5 总结

本文摘取 ConcurrentHashMap 两个核心的方法讲解了一下，特别是 put 方法，采取了很多手段来保证了线程安全，是平时面试时的重中之重，大家可以尝试 debug 来调试一下源码，其他方法感兴趣的话，可以尝试去 GitHub 上去查看源码。

[15 CopyOnWriteArrayList 源码解析和设计思路](https://www.imooc.com/read/47/article/857)[17 并发 List、Map源码面试题](https://www.imooc.com/read/47/article/859)

精选留言 15

欢迎在这里发表留言，作者筛选后可公开显示

- [qq_起风了_90](https://www.imooc.com/u/4215153/articles)

  老师，我在调试代码的时候，存储二个键值对，map.put("a",1); map.put("a",2);在调试源代的时候，运行到这段代码，if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } 这时候oldVal的值是1，但是跳出循环后，值怎么变成2了呢？这个过程是怎么变的，看不出来啊

   0

  回复

  2019-12-09

- [宣告不幸的黑猫](https://www.imooc.com/u/4123115/articles)

  老师，Jdk1.8之前的版本是怎么实现concurrentHashMap的

   0

  回复

  2019-12-06

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[宣告不幸的黑猫](https://www.imooc.com/u/4123115/articles)

    同学你好，核心思想就是通过分段+加锁。

    回复

    2019-12-08 13:16:26

- [鬼魅的程序涌上心头](https://www.imooc.com/u/7620802/articles)

  扩容时会将扩容过后的槽点变为转移节点,那什么时候将转移节点设置成普通节点呢?是不是扩容完成将新数组拷贝成element数组的时候?

   1

  回复

  2019-11-25

  - [风舞炫动](https://www.imooc.com/u/6409329/articles)

    回复[鬼魅的程序涌上心头](https://www.imooc.com/u/7620802/articles)

    不会设置了，等全部拷贝完了直接给容器赋值新数组。原来的相当于等着jvm来回收了，已经没啥用了

    回复

    2019-11-27 18:08:08

- [weixin_慕工程5089940](https://www.imooc.com/u/8217835/articles)

  老师为什么他已经用sync锁住了槽点了为什么还要用写锁来锁树根啊？

   1

  回复

  2019-11-07

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[weixin_慕工程5089940](https://www.imooc.com/u/8217835/articles)

    因为槽点上的第一个值，不一定是红黑树的根节点。

    回复

    2019-11-17 11:06:31

- [licly](https://www.imooc.com/u/8096709/articles)

  node节点里面的属性为什么要加volatile呢，看网上说是为了保证table数组元素的可见性，但是数组元素赋值是在node赋值后面的，volatile只能保证它前面操作的可见性吧

   0

  回复

  2019-11-06

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    个人理解，Node.next 在大量自旋操作中被使用，自旋操作相对其他操作来说，是比较耗时的，volatile 可以最大程度的保证自旋时的数据是最新的。

    回复

    2019-11-17 11:04:30

- [慕盖茨4571687](https://www.imooc.com/u/6882674/articles)

  该槽点进行扩容时什么意思，不是这个map进行扩容吗？

   0

  回复

  2019-10-28

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[慕盖茨4571687](https://www.imooc.com/u/6882674/articles)

    //如果当前槽点是转移节点，表示该槽点正在扩容，就会一直等待扩容完成 是这句话么，你说的对，是Map正在扩容，这句话主要想表达的是扩容正好进行到这个槽点了。

    回复

    2019-10-31 11:34:41

- [licly](https://www.imooc.com/u/8096709/articles)

  老师，指定容量的构造方法ConcurrentHashMap(int initialCapacity)，调用tableSizeFor的时候，为什么要传initialCapacity + (initialCapacity >>> 1) + 1，而不是像hashmap一样直接传入initialCapacity

   0

  回复

  2019-10-16

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    同学你好，原理应该在 《高效程序的奥秘》3.2 小节，我看了没有看懂，不敢乱说，你有兴趣的话可以看看，目的是提高性能。

    回复

    2019-10-17 19:37:21

- [qq_现实点_03300102](https://www.imooc.com/u/3300102/articles)

  //如果当前槽点是转移节点，表示该槽点正在扩容，就会一直等待扩容完成 //转移节点的 hash 值是固定的，都是 MOVED else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); 老师,这个是当前槽点正在扩容,线程会帮着一起扩容吧?不是一直等待扩容完成吧?

   0

  回复

  2019-10-15

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[qq_现实点_03300102](https://www.imooc.com/u/3300102/articles)

    同学你好，transfer 方法里面数据拷贝时，是加锁的，同一时刻，只能一个线程执行数据拷贝，helpTransfer 方法比较复杂，理解起来很困难，所以说等待拷贝会更加容易理解一点，但你说的一点都没错的，方法注释上面写的是帮助。

    回复

    2019-10-15 20:10:39

- [licly](https://www.imooc.com/u/8096709/articles)

  老师，transfer方法，if (U.compareAndSetInt(this, SIZECTL, sc = sizeCtl, sc - 1))语句中， if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)这个判断不太理解。为什么(sc - 2)和 resizeStamp(n) << RESIZE_STAMP_SHIFT不相等就表示扩容没结束，相等了就表示扩容结束呢？

   0

  回复

  2019-10-14

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    这个主要是因为在调用 transfer 之前，都有 U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2) 的操作，((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) 正是其逆过程，如果相等，那么扩容就结束了。

    回复

    2019-10-15 20:53:16

- [weixin_慕婉清1547377](https://www.imooc.com/u/8136744/articles)

  想努力看懂，但是还是看不懂，怎么办

   0

  回复

  2019-10-11

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[weixin_慕婉清1547377](https://www.imooc.com/u/8136744/articles)

    理解哈，我第一次看源码的时候和你一样的困惑，源码的逻辑看着都头疼，但我会尝试的反复的看，反复的 debug，特别是 debug 时，看着运行时的数据，理解会容易很多，我相信你也可以的，静下心来，反复看，反复 debug，肯定是可以的。

    回复

    2019-10-12 18:58:25

- [licly](https://www.imooc.com/u/8096709/articles)

  扩容的时候，stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE。 为什么要用n >>> 8呢？

   0

  回复

  2019-10-10

  - [慕仰0328976](https://www.imooc.com/u/8085349/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    我是这么理解的：transfer主要和上一版的优化点就是支持多线程同时扩容，也就是一个线程在扩容的时候，如果有另一个线程进来了不会阻塞会帮助它一起扩容，如果理解了stride的意思的话就会明白，其实作者是先把n分成多组每组的大小是stride，然后每一个线程扩容的时候拿一组自己处理互不干涉，这种时候最好的情况就是这个电脑下所有能用的线程都来扩容效率最高，那就应该分成（NCPU * 每个CPU下的线程数）组，但是因为每个CPU下的可用线程是自己配的，作者也不知道会是多少，所以定了一个普遍的值8，因为右移比除法快所以用右移。

    回复

    2019-10-12 18:54:36

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[慕仰0328976](https://www.imooc.com/u/8085349/articles)

    同学分析有道理，给你点赞。

    回复

    2019-10-12 18:55:56

- [licly](https://www.imooc.com/u/8096709/articles)

  老师，为什么CopyOnWriteArrayList需要赋值数组触发volatile可见性，而ConcurrentHashMap不需要呢，他为什么就可以

   0

  回复

  2019-10-08

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    ConcurrentHashMap 在扩容时，table 的内存地址也是会变的哦，也会触发 volatile 的特性哈。

    回复

    2019-10-08 13:14:05

  - [licly](https://www.imooc.com/u/8096709/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    map不扩容的时候，插入数据怎么对其他线程保证可见的呢，这个时候也没触发volatile

    回复

    2019-10-08 21:08:06

  - [licly](https://www.imooc.com/u/8096709/articles)

    回复

    [文贺](https://www.imooc.com/u/8062574/articles)

    concurrentHashMap不扩容的时候，插入数据，怎么对其他线程保证可见的呢，这个时候，也没有触发volatile

    回复

    2019-10-08 21:09:38

  点击展开后面 5 条

- [licly](https://www.imooc.com/u/8096709/articles)

  老师，initTable方法中，双重check防止的是什么情况呢，老师可以举个例子吗

   0

  回复

  2019-10-05

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    正常来说，CAS 已经保证只有一个线程才能初始化 table，但有一点需要注意的是：SIZECTL 的值不仅仅是 initTable 这一个值在修改，比如说 transfer，addCount 方法也在用，猜测可能会有一种极限情况，正好修改了 SIZECTL 的值，使其不等于-1，导致另一个线程也能够 CAS 成功，这只是猜测。但从源码上看，的确是进行了双重 check，这也是一种初始化默认的条约吧，我们在写单例模式的时候，在项目启动初始化值的时候，也会双重 check。

    回复

    2019-10-08 19:02:20

- [licly](https://www.imooc.com/u/8096709/articles)

  老师，怎么在源码上加注释呢，就像你GitHub上的代码一样。我这里源码都是只读的，不能修改

   0

  回复

  2019-10-05

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    其实我的也是只读的，注释是我看源码的时候加上去的，并不是边注释边加的。

    回复

    2019-10-08 19:08:15

  - [licly](https://www.imooc.com/u/8096709/articles)

    回复

    [文贺](https://www.imooc.com/u/8062574/articles)

    那怎么让他可编辑呢，我也想在上面加注释

    回复

    2019-10-08 19:18:00

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[licly](https://www.imooc.com/u/8096709/articles)

    那你需要下载 JDK 的源码，然后把源码拷贝到 Maven 新项目中，就可以导入 IDEA 中了，就像咱们源码注释一样。

    回复

    2019-10-08 19:38:58

- [一个被女人上过的男人](https://www.imooc.com/u/6320083/articles)

  老师，你拷贝函数那块，i是从最大长度的位置开始的，你写的0

   0

  回复

  2019-10-04

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[一个被女人上过的男人](https://www.imooc.com/u/6320083/articles)

    哪行代码？请指教哈。

    回复

    2019-10-08 19:07:43

 

千学不如一看，千看不如一练

 

# 17 并发 List、Map源码面试题

17 并发 List、Map源码面试题

更新时间：2019-10-09 05:44:11

![img](https://img4.mukewang.com/5d89769e0001139406400359.jpg)

![img](https://www.imooc.com/static/img/column/bg-l.png)![img](https://www.imooc.com/static/img/column/bg-r.png)

梦想只要能持久，就能成为现实。我们不就是生活在梦想中的吗？

——丁尼生



## 引导语

并发 List 和 Map 是技术面时常问的问题，问的问题也都比较深入，有很多问题都是面试官自创的，市面上找不到，所以说通过背题的方式，这一关大部分是过不了的，只有我们真正理解了 API 内部的实现，阅读过源码，才能自如应对各种类型的面试题，接着我们来看一下并发 List、Map 源码相关的面试题集。



## 1 CopyOnWriteArrayList 相关



### 1.1 和 ArrayList 相比有哪些相同点和不同点？

答：相同点：底层的数据结构是相同的，都是数组的数据结构，提供出来的 API 都是对数组结构进行操作，让我们更好的使用。

不同点：后者是线程安全的，在多线程环境下使用，无需加锁，可直接使用。



### 1.2 CopyOnWriteArrayList 通过哪些手段实现了线程安全？

答：主要有：1. 数组容器被 volatile 关键字修饰，保证了数组内存地址被任意线程修改后，都会通知到其他线程；

1. 对数组的所有修改操作，都进行了加锁，保证了同一时刻，只能有一个线程对数组进行修改，比如我在 add 时，就无法 remove；
2. 修改过程中对原数组进行了复制，是在新数组上进行修改的，修改过程中，不会对原数组产生任何影响。

通过以上三点保证了线程安全。



### 1.3 在 add 方法中，对数组进行加锁后，不是已经是线程安全了么，为什么还需要对老数组进行拷贝？

答：的确，对数组进行加锁后，能够保证同一时刻，只有一个线程能对数组进行 add，在同单核 CPU 下的多线程环境下肯定没有问题，但我们现在的机器都是多核 CPU，如果我们不通过复制拷贝新建数组，修改原数组容器的内存地址的话，是无法触发 volatile 可见性效果的，那么其他 CPU 下的线程就无法感知数组原来已经被修改了，就会引发多核 CPU 下的线程安全问题。

假设我们不复制拷贝，而是在原来数组上直接修改值，数组的内存地址就不会变，而数组被 volatile 修饰时，必须当数组的内存地址变更时，才能及时的通知到其他线程，内存地址不变，仅仅是数组元素值发生变化时，是无法把数组元素值发生变动的事实，通知到其它线程的。



### 1.4 对老数组进行拷贝，会有性能损耗，我们平时使用需要注意什么么？

答：主要有：

1. 在批量操作时，尽量使用 addAll、removeAll 方法，而不要在循环里面使用 add、remove 方法，主要是因为 for 循环里面使用 add 、remove 的方式，在每次操作时，都会进行一次数组的拷贝(甚至多次)，非常耗性能，而 addAll、removeAll 方法底层做了优化，整个操作只会进行一次数组拷贝，由此可见，当批量操作的数据越多时，批量方法的高性能体现的越明显。



### 1.5 为什么 CopyOnWriteArrayList 迭代过程中，数组结构变动，不会抛出ConcurrentModificationException 了

答：主要是因为 CopyOnWriteArrayList 每次操作时，都会产生新的数组，而迭代时，持有的仍然是老数组的引用，所以我们说的数组结构变动，是用新数组替换了老数组，老数组的结构并没有发生变化，所以不会抛出异常了。



### 1.6 插入的数据正好在 List 的中间，请问两种 List 分别拷贝数组几次？为什么？

答：ArrayList 只需拷贝一次，假设插入的位置是 2，只需要把位置 2 （包含 2）后面的数据都往后移动一位即可，所以拷贝一次。

CopyOnWriteArrayList 拷贝两次，因为 CopyOnWriteArrayList 多了把老数组的数据拷贝到新数组上这一步，可能有的同学会想到这种方式：先把老数组拷贝到新数组，再把 2 后面的数据往后移动一位，这的确是一种拷贝的方式，但 CopyOnWriteArrayList 底层实现更加灵活，而是：把老数组 0 到 2 的数据拷贝到新数组上，预留出新数组 2 的位置，再把老数组 3～ 最后的数据拷贝到新数组上，这种拷贝方式可以减少我们拷贝的数据，虽然是两次拷贝，但拷贝的数据却仍然是老数组的大小，设计的非常巧妙。



## 2 ConcurrentHashMap 相关



### 2.1ConcurrentHashMap 和 HashMap 的相同点和不同点

答：相同点：1. 都是数组 + 链表 +红黑树的数据结构，所以基本操作的思想相同；

1. 都实现了 Map 接口，继承了 AbstractMap 抽象类，所以两者的方法大多都是相似的，可以互相切换。

不同点：1. ConcurrentHashMap 是线程安全的，在多线程环境下，无需加锁，可直接使用；

1. 数据结构上，ConcurrentHashMap 多了转移节点，主要用于保证扩容时的线程安全。



### 2.2 ConcurrentHashMap 通过哪些手段保证了线程安全。

答：主要有以下几点：

1. 储存 Map 数据的数组被 volatile 关键字修饰，一旦被修改，立马就能通知其他线程，因为是数组，所以需要改变其内存值，才能真正的发挥出 volatile 的可见特性；
2. put 时，如果计算出来的数组下标索引没有值的话，采用无限 for 循环 + CAS 算法，来保证一定可以新增成功，又不会覆盖其他线程 put 进去的值；
3. 如果 put 的节点正好在扩容，会等待扩容完成之后，再进行 put ，保证了在扩容时，老数组的值不会发生变化；
4. 对数组的槽点进行操作时，会先锁住槽点，保证只有当前线程才能对槽点上的链表或红黑树进行操作；
5. 红黑树旋转时，会锁住根节点，保证旋转时的线程安全。



### 2.3 描述一下 CAS 算法在 ConcurrentHashMap 中的应用？

答：CAS 其实是一种乐观锁，一般有三个值，分别为：赋值对象，原值，新值，在执行的时候，会先判断内存中的值是否和原值相等，相等的话把新值赋值给对象，否则赋值失败，整个过程都是原子性操作，没有线程安全问题。

ConcurrentHashMap 的 put 方法中，有使用到 CAS ，是结合无限 for 循环一起使用的，步骤如下：

1. 计算出数组索引下标，拿出下标对应的原值；
2. CAS 覆盖当前下标的值，赋值时，如果发现内存值和 1 拿出来的原值相等，执行赋值，退出循环，否则不赋值，转到 3；
3. 进行下一次 for 循环，重复执行 1，2，直到成功为止。

可以看到这样做的好处，第一是不会盲目的覆盖原值，第二是一定可以赋值成功。



### 2.4 ConcurrentHashMap 是如何发现当前槽点正在扩容的。

答：ConcurrentHashMap 新增了一个节点类型，叫做转移节点，当我们发现当前槽点是转移节点时（转移节点的 hash 值是 -1），即表示 Map 正在进行扩容。



### 2.5 发现槽点正在扩容时，put 操作会怎么办？

答：无限 for 循环，或者走到扩容方法中去，帮助扩容，一直等待扩容完成之后，再执行 put 操作。



### 2.6 两种 Map 扩容时，有啥区别？

答：区别很大，HashMap 是直接在老数据上面进行扩容，多线程环境下，会有线程安全的问题，而 ConcurrentHashMap 就不太一样，扩容过程是这样的：

1. 从数组的队尾开始拷贝；
2. 拷贝数组的槽点时，先把原数组槽点锁住，拷贝成功到新数组时，把原数组槽点赋值为转移节点；
3. 从数组的尾部拷贝到头部，每拷贝成功一次，就把原数组的槽点设置成转移节点；
4. 直到所有数组数据都拷贝到新数组时，直接把新数组整个赋值给数组容器，拷贝完成。

简单来说，通过扩容时给槽点加锁，和发现槽点正在扩容就等待的策略，保证了 ConcurrentHashMap 可以慢慢一个一个槽点的转移，保证了扩容时的线程安全，转移节点比较重要，平时问的人也比较多。



### 2.7 ConcurrentHashMap 在 Java 7 和 8 中关于线程安全的做法有啥不同？

答：非常不一样，拿 put 方法为例，Java 7 的做法是：

1. 把数组进行分段，找到当前 key 对应的是那一段；
2. 将当前段锁住，然后再根据 hash 寻找对应的值，进行赋值操作。

Java 7 的做法比较简单，缺点也很明显，就是当我们需要 put 数据时，我们会锁住改该数据对应的某一段，这一段数据可能会有很多，比如我只想 put 一个值，锁住的却是一段数据，导致这一段的其他数据都不能进行写入操作，大大的降低了并发性的效率。Java 8 解决了这个问题，从锁住某一段，修改成锁住某一个槽点，提高了并发效率。

不仅仅是 put，删除也是，仅仅是锁住当前槽点，缩小了锁的范围，增大了效率。



## 3 总结

因为目前大多数公司都已经在使用 Java 8 了，所以大部分面试内容还是以 Java 8 的 API 为主，特别是 CopyOnWriteArrayList 和 ConcurrentHashMap 两个 API，文章毕竟篇幅有限，建议大家多多阅读剩余源码。

[16 ConcurrentHashMap 源码解析和设计思路](https://www.imooc.com/read/47/article/858)[18 场景集合：并发 List、Map的应用场景](https://www.imooc.com/read/47/article/860)

精选留言 4

欢迎在这里发表留言，作者筛选后可公开显示

- [wt4446](https://www.imooc.com/u/3616005/articles)

  槽点？啥意思

   0

  回复

  2019-11-30

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[wt4446](https://www.imooc.com/u/3616005/articles)

    在 JDK1.8 中表示数组中的某一个元素。

    回复

    2019-12-08 13:56:46

- [慕仙6328494](https://www.imooc.com/u/7573629/articles)

  老师, CopyOnWriteArrayList中你说volatile修饰数组是保证可见性,必须数组内存地址改变才触发, 而ConcurrentHashMap用volatile修饰数组怎么保证可见性呢,内存地址也不变啊

   0

  回复

  2019-11-23

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[慕仙6328494](https://www.imooc.com/u/7573629/articles)

    ConcurrentHashMap 不仅仅 table 是用 volatile 修饰的，table 里面的元素 Node 的 val 和 next 都是用 volatile 修饰的，这个是关键。

    回复

    2019-11-30 13:32:58

- [weixin_慕工程5089940](https://www.imooc.com/u/8217835/articles)

  老师你写的 HashMap 是直接在老数据上面进行扩容 这句话怎么理解啊？

   0

  回复

  2019-11-14

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[weixin_慕工程5089940](https://www.imooc.com/u/8217835/articles)

    这个是和 ConcurrentHashMap 的扩容相对而言的，HashMap 扩展是直接在 oldTable 上操作的，ConcurrentHashMap 则不同，ConcurrentHashMap 的如果操作的可以看看文章描述哈。

    回复

    2019-11-17 10:45:15

- [街边七号](https://www.imooc.com/u/4803117/articles)

  2.3 `CAS其实是一种悲观锁`, 此处是否笔误了。

   0

  回复

  2019-10-04

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[街边七号](https://www.imooc.com/u/4803117/articles)

    是的，练习编辑更正中，谢谢

    回复

    2019-10-08 19:15:05

  - [慕容8344055](https://www.imooc.com/u/7161763/articles)

    回复[街边七号](https://www.imooc.com/u/4803117/articles)

    CAS为什么是悲观锁，可以解释一下吗

    回复

    2019-12-20 10:25:32

  - [OO行胜于言](https://www.imooc.com/u/3004336/articles)

    回复[慕容8344055](https://www.imooc.com/u/7161763/articles)

    笔者笔误了，是乐观锁。

    回复

    2019-12-26 16:01:04

 

千学不如一看，千看不如一练

# 18 场景集合：并发 List、Map的应用场景

18 场景集合：并发 List、Map的应用场景

更新时间：2019-10-08 16:45:03

![img](https://img.mukewang.com/5d919821000109d506400359.jpg)

![img](https://www.imooc.com/static/img/column/bg-l.png)![img](https://www.imooc.com/static/img/column/bg-r.png)

一个不注意小事情的人，永远不会成功大事业。

——戴尔·卡耐基



## 引导语

并发 List、Map 使用最多的就是 CopyOnWriteArrayList 和 ConcurrentHashMap，在考虑 API 时，我们也无需迟疑，这两个并发类在安全和性能方面都很好，我们都可以直接使用。

并发的场景很多，但归根结底其实就是共享变量被多个线程同时访问，也就是说 CopyOnWriteArrayList 或 ConcurrentHashMap 会被作为共享变量，本节我们会以流程引擎为案例，现身说法，增加一下大家的工作经验积累。

流程引擎在实际工作中经常被使用，其主要功能就是对我们需要完成的事情，进行编排和组装，比如在淘宝下单流程中，我们一共会执行 20 个 Spring Bean，流程引擎就可以帮助我们调起 20 个 Spring Bean，并帮助我们去执行，本文介绍的重点在于如何使用 Map + List 来设计流程引擎的数据结构，以及其中需要注意到的线程安全的问题。



## 1 嵌套 Map，简单流程引擎

市面上有很多流程引擎，比如说 Activiti、Flowable、Camunda 等等，功能非常齐全，但我们本小节只实现一种最最简单的流程引擎，只要能对我们需要完成的事情进行编排，并能依次的调用就行。



### 1.1 流程引擎设计思路

我们认为每个流程都会做 4 个阶段的事情，阶段主要是指在整个流程中，大概可以分为几个大的步骤，每个阶段可以等同为大的步骤，分别如下：

1. 参数校验，主要是对流程的入参数进行校验；
2. 业务校验，主要是对当前流程中的业务进行逻辑校验；
3. 事务中落库，主要把数据落库，控制事务；
4. 事务后事件，我们在数据落库，事务提交之后，可能会做一些其他事情，比如说发消息出来等等。

以上每个大的阶段，都会做一些粒度较细的事情，比如说业务校验，我们可能会对两个业务对象进行校验，那么此时业务校验阶段就会做两件事情，每件具体的事情，我们叫做领域行为，在实际项目中，一个领域行为一般都是一个 Spring Bean。

综上所述，流程引擎嵌套数据结构就是：流程 -> 阶段 -> 领域行为，前者对应后者，都是一对一或者一对多的关系。

我们以在淘宝上买东西时，下单为例，下单指的是我们在淘宝选择好了商品和优惠券后，点击购买按钮时触发的动作。

为了方便举例，我们假设在淘宝上买电视和电影票，在后端，会分别对应着两个下单流程，我们画图示意一下：
![图片描述](https://img.mukewang.com/5d88856f000149cd12740928.png)
上图中，左右两个黑色长方形大框代表着两个流程，流程下面有多个阶段，阶段用蓝色表示，每个阶段下面有多个领域行为，用红色表示。

可以看到两个流程中，都包含有四个阶段，阶段都是相同的，但每个阶段中的领域行为，有的相同，有的却是特有的。

三个概念，每个概念层层嵌套，整体组装起来，用来表示一个流程，那么这个数据结构，我们应该如何表示呢？

使用 Map + List 即可！



### 1.2 数据结构的定义

流程的数据结构定义分成两步：

1. 定义出阶段、领域行为基础概念；
2. 把阶段、领域行为、流程概念组合起来，定义出流程的数据结构。

首先给阶段定义一个枚举，如下 StageEnum 代表流程中的阶段或步骤：

```java
public enum StageEnum {
  PARAM_VALID("PARAM_VALID", "参数校验"),

  BUSINESS_VALID("BUSINESS_VALID", "业务校验"),

  IN_TRANSACTION("IN_TRANSACTION", "事务中落库"),

  AFTER_TRANSACTION("AFTER_TRANSACTION", "事务后事件"),
  ;

  private String code;
  private String desc;

  StageEnum(String code, String desc) {
    this.code = code;
    this.desc = desc;
  }
}
```

领域行为我们无需定义，目前通用的技术框架都是 Spring Boot，领域行为都是 Spring Bean，为了简单起见，我们给领域行为定义了一个接口，每个领域行为都要实现这个接口，方便我们编排，接口如下：

```java
/**
 * 领域行为
 * author  wenhe
 * date 2019/8/11
 */
public interface DomainAbilityBean {

  /**
   * 领域行为的方法入口
   */
  FlowContent invoke(FlowContent content);

}
```

接着我们使用 Map + List 来定义流程，定义如下：

```java
/**
 * 第一个 key 是流程的名字
 * 第二个 map 的 key 是阶段，为 StageEnum 枚举，值为多个领域行为的集合
 */
Map<String,Map<StageEnum,List<DomainAbilityBean>>> flowMap
```

至此，我们定义出了，简单流程引擎的数据结构，流程引擎看着很复杂，利用 Map + List 的组合，就巧妙的定义好了。



## 2 容器初始化时，本地缓存使用

我们定义好 Map 后，我们就需要去使用他，我们使用的大体步骤为：

1. 项目启动时，把所有的流程信息初始化到 flowMap(刚刚定义的流程的数据结构叫做 flowMap) 中去，可能是从数据库中加载，也可能是从 xml 文件中加载；
2. 查找流程时，直接从 flowMap 中获取即可。



### 2.1 初始化

以上两步最为关键的点就是 flowMap 必须是可以随时访问到的，所有我们会把 flowMap 作为共享变量使用，也就是会被 static final 关键字所修饰，我们首先来 mock 一下把所有信息初始化到 flowMap 中去的代码，如下：

```java
@Component
public class FlowCenter {

  /**
   * flowMap 是共享变量，方便访问，并且是 ConcurrentHashMap
   */
  public static final Map<String, Map<StageEnum, List<DomainAbilityBean>>> flowMap
      = Maps.newConcurrentMap();

  /**
   * PostConstruct 注解的意思就是
   * 在容器启动成功之后，执行 init 方法，初始化 flowMap
   */
  @PostConstruct
  public void init() {
      // 初始化 flowMap，可能是从数据库，或者 xml 文件中加载 map
  }

}
```

以上代码，关键地方在于三点：

1. flowMap 被 static final 修饰，是个共享变量，方便访问；
2. flowMap 是 ConcurrentHashMap，所以我们所有的操作都无需加锁，比如我们在 init 方法中，对 flowMap 进行初始化，就无需加锁，因为 ConcurrentHashMap 本身已经保证了线程安全；
3. 这里我们初始化的时机是在容器启动的时候，在实际的工作中，我们经常在容器启动的时候，把不会经常发生变动的数据，放到类似 List、Map 这样的共享变量中，这样当我们频繁要使用的时候，直接从内存中读取即可。



### 2.2 使用

那我们实际使用的时候，只需要告诉 flowMap 当前是那个流程的那个阶段，就可以返回该流程该阶段下面的所有领域行为了，我们写了一个流程引擎使用的工具类入口，如下：

```java
// 流程引擎对外的 API
public class FlowStart {

  /**
   * 流程引擎开始
   *
   * @param flowName 流程的名字
   */
  public void start(String flowName, FlowContent content) {
    invokeParamValid(flowName, content);
    invokeBusinessValid(flowName, content);
    invokeInTramsactionValid(flowName, content);
    invokeAfterTramsactionValid(flowName, content);
  }
  // 执行参数校验
  private void invokeParamValid(String flowName, FlowContent content) {
    stageInvoke(flowName, StageEnum.PARAM_VALID, content);
  }
  // 执行业务校验
  private void invokeBusinessValid(String flowName, FlowContent content) {
    stageInvoke(flowName, StageEnum.BUSINESS_VALID, content);
  }
  // 执行事务中
  private void invokeInTramsactionValid(String flowName, FlowContent content) {
    stageInvoke(flowName, StageEnum.IN_TRANSACTION, content);
  }
  // 执行事务后
  private void invokeAfterTramsactionValid(String flowName, FlowContent content) {
    stageInvoke(flowName, StageEnum.AFTER_TRANSACTION, content);
  }
		
  // 批量执行 Spring Bean
  private void stageInvoke(String flowName, StageEnum stage, FlowContent content) {
    List<DomainAbilityBean>
        domainAbilitys =
        FlowCenter.flowMap.getOrDefault(flowName, Maps.newHashMap()).get(stage);
    if (CollectionUtils.isEmpty(domainAbilitys)) {
      throw new RuntimeException("找不到该流程对应的领域行为" + flowName);
    }
    for (DomainAbilityBean domainAbility : domainAbilitys) {
      domainAbility.invoke(content);
    }
  }

}
```

从代码中可以看到，我们在流程引擎的入口，只要根据参数校验、业务校验、事务中、事务后四个阶段，从 flowMap 中得到领域行为的集合，然后对领域行为进行顺序执行即可。

我们在使用时，直接使用上述类的 start 方法即可。

当然以上演示的流程引擎只是一个大的框架，还有很多地方需要改进的地方，比如如何找到 flowName，如何初始化 flowMap，但这些都不是本节重点，本节主要想通过流程引擎案例来说明几点：

1. 把 List 和 Map 作为共享变量非常常见，就像咱们这种项目启动时，从数据库中把数据捞出来，然后封装成 List 或 Map 的结构，这样做的优点就是节约资源，不用每次用的时候都去查数据库，直接从内存中获取即可；
2. 并发场景下，我们可以放心的使用 CopyOnWriteArrayList 和 ConcurrentHashMap 两个并发类，首先用 static final 对两者进行修饰，使其成为共享变量，接着在写入或者查询的时候，无需加锁，两个 API 内部已经实现了加锁的功能了；
3. 有一点需要澄清一下，就是 CopyOnWriteArrayList 和 ConcurrentHashMap 只能作为单机的共享变量，如果是分布式系统，多台机器的情况下，这样做不行了，需要使用分布式缓存了。



## 3 总结

本节内容，以流程引擎为例，说明了如何使用 Map + List 的嵌套结构设计流程引擎，以及在并发情况下，如何安全的使用 List 和 Map。

本案列是高并发项目的真实案例，感兴趣的同学可以在此流程引擎框架基础上进行细节补充，实现可运行的流程引擎。

[17 并发 List、Map源码面试题](https://www.imooc.com/read/47/article/859)[19 LinkedBlockingQueue 源码解析](https://www.imooc.com/read/47/article/861)

精选留言 2

欢迎在这里发表留言，作者筛选后可公开显示

- [_LJ](https://www.imooc.com/u/5380221/articles)

  老师，我在学习专栏时，一般都是看到每一段话，然后用自己的话翻译一遍，然后记到自己的笔记，不然感觉过了一段时间就忘了，这个翻译的过程也是把知识点在自己的脑子中过一遍，思考一遍的过程，记忆也会更加深刻，不知道这样的方式合理吗？

   0

  回复

  2019-10-09

  - [文贺](https://www.imooc.com/u/8062574/articles)

    回复[_LJ](https://www.imooc.com/u/5380221/articles)

    棒，我觉得蛮好的哈，我虽然不是强化记忆方面的专家，但也看过这方面的文章，这应该叫做加深理解，刻意练习，保持加油，如果能写写demo，多多debug就更好了。

    回复

    2019-10-10 22:59:01

- [文贺](https://www.imooc.com/u/8062574/articles)

  demo.three.flow.* 目录下的代码可能和文章的不太一样，因为这个流程引擎的例子，我们会在第七章线程池的章节中再次实践，所以 GitHub 的代码可能和文章不太一样，GitHub 的代码是加上线程池内容的代码，文章中的代码是没有加线程池内容的代码。

   0

  回复

  2019-10-08

 

千学不如一看，千看不如一练

 